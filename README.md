# Amazon Product Scraper

Um sistema completo de web scraping para extrair dados de produtos da Amazon, desenvolvido com Flask (backend) e HTML/CSS/JavaScript (frontend).

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#visÃ£o-geral)
- [CaracterÃ­sticas](#caracterÃ­sticas)
- [Arquitetura](#arquitetura)
- [PrÃ©-requisitos](#prÃ©-requisitos)
- [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
- [Uso](#uso)
- [API Endpoints](#api-endpoints)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [Tecnologias Utilizadas](#tecnologias-utilizadas)
- [LimitaÃ§Ãµes e ConsideraÃ§Ãµes](#limitaÃ§Ãµes-e-consideraÃ§Ãµes)
- [ContribuiÃ§Ã£o](#contribuiÃ§Ã£o)
- [LicenÃ§a](#licenÃ§a)

## ğŸ¯ VisÃ£o Geral

O Amazon Product Scraper Ã© uma aplicaÃ§Ã£o web que permite extrair informaÃ§Ãµes de produtos da Amazon de forma automatizada. O sistema consiste em um backend Flask que realiza o web scraping e uma interface web moderna que permite aos usuÃ¡rios pesquisar produtos e visualizar os resultados de forma organizada.

### Funcionalidades Principais

- **Interface Web Intuitiva**: Interface moderna e responsiva para pesquisa de produtos
- **API RESTful**: Endpoints bem documentados para integraÃ§Ã£o com outras aplicaÃ§Ãµes
- **ExtraÃ§Ã£o de Dados**: Coleta tÃ­tulo, classificaÃ§Ã£o, nÃºmero de avaliaÃ§Ãµes, imagens e preÃ§os
- **Tratamento de Erros**: Sistema robusto de tratamento de erros e validaÃ§Ã£o
- **Design Responsivo**: Interface adaptÃ¡vel para desktop e dispositivos mÃ³veis

## âœ¨ CaracterÃ­sticas

### Backend (Flask)
- âœ… API RESTful com endpoints documentados
- âœ… Web scraping com BeautifulSoup e requests
- âœ… Tratamento robusto de erros
- âœ… ConfiguraÃ§Ã£o CORS para integraÃ§Ã£o frontend
- âœ… ValidaÃ§Ã£o de parÃ¢metros de entrada
- âœ… Headers personalizados para evitar detecÃ§Ã£o de bot

### Frontend (HTML/CSS/JavaScript)
- âœ… Interface moderna com design profissional
- âœ… FormulÃ¡rio de pesquisa com validaÃ§Ã£o
- âœ… ExibiÃ§Ã£o de resultados em grid responsivo
- âœ… Estados de carregamento e erro
- âœ… IntegraÃ§Ã£o AJAX com o backend
- âœ… AnimaÃ§Ãµes e transiÃ§Ãµes suaves

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    HTTP/AJAX    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚                 â”‚
â”‚   Frontend      â”‚                 â”‚   Backend       â”‚
â”‚   (Vite)        â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚   (Flask)       â”‚
â”‚   Port: 5173    â”‚    JSON API     â”‚   Port: 5001    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                             â”‚
                                             â”‚ HTTP Requests
                                             â–¼
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚                 â”‚
                                    â”‚   Amazon.com    â”‚
                                    â”‚   (Web Scraping)â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Fluxo de Dados

1. **UsuÃ¡rio** insere palavra-chave na interface web
2. **Frontend** envia requisiÃ§Ã£o AJAX para o backend
3. **Backend** processa a requisiÃ§Ã£o e faz scraping da Amazon
4. **Backend** retorna dados estruturados em JSON
5. **Frontend** exibe os resultados de forma organizada

## ğŸ“‹ PrÃ©-requisitos

Antes de executar o projeto, certifique-se de ter instalado:

- **Python 3.8+** - Para o backend Flask
- **Node.js 16+** - Para o frontend Vite
- **pip** - Gerenciador de pacotes Python
- **npm** - Gerenciador de pacotes Node.js

### Verificar InstalaÃ§Ãµes

```bash
# Verificar Python
python3 --version

# Verificar Node.js
node --version

# Verificar npm
npm --version
```

## ğŸš€ InstalaÃ§Ã£o

### 1. Clonar o RepositÃ³rio

```bash
git clone <url-do-repositorio>
cd amazon-scraper
```

### 2. Configurar Backend

```bash
# Navegar para o diretÃ³rio do backend
cd backend

# Criar ambiente virtual
python3 -m venv venv

# Ativar ambiente virtual
# No Linux/Mac:
source venv/bin/activate
# No Windows:
# venv\Scripts\activate

# Instalar dependÃªncias
pip install -r requirements.txt
```

### 3. Configurar Frontend

```bash
# Navegar para o diretÃ³rio do frontend
cd ../frontend

# Instalar dependÃªncias
npm install
```

## ğŸ® Uso

### Executar o Backend

```bash
# No diretÃ³rio backend/
source venv/bin/activate
python src/main.py
```

O backend estarÃ¡ disponÃ­vel em: `http://localhost:5001`

### Executar o Frontend

```bash
# No diretÃ³rio frontend/
npm run dev
```

O frontend estarÃ¡ disponÃ­vel em: `http://localhost:5173`

### Usar a AplicaÃ§Ã£o

1. Abra o navegador e acesse `http://localhost:5173`
2. Digite uma palavra-chave no campo de pesquisa (ex: "notebook")
3. Selecione o nÃºmero mÃ¡ximo de produtos desejado
4. Clique em "Buscar Produtos"
5. Aguarde os resultados serem exibidos

## ğŸ”Œ API Endpoints

### Base URL
```
http://localhost:5001/api
```

### Endpoints DisponÃ­veis

#### 1. Health Check
```http
GET /health
```

**Resposta:**
```json
{
  "status": "healthy",
  "service": "Amazon Scraper API",
  "timestamp": 1754662666.9606373
}
```

#### 2. Scraping de Produtos
```http
GET /scrape?keyword={palavra-chave}&max_products={numero}
```

**ParÃ¢metros:**
- `keyword` (obrigatÃ³rio): Palavra-chave para pesquisar
- `max_products` (opcional): NÃºmero mÃ¡ximo de produtos (1-50, padrÃ£o: 20)

**Exemplo:**
```http
GET /scrape?keyword=notebook&max_products=10
```

**Resposta de Sucesso:**
```json
{
  "success": true,
  "keyword": "notebook",
  "total_products": 10,
  "execution_time": 2.34,
  "search_url": "https://www.amazon.com.br/s?k=notebook",
  "products": [
    {
      "title": "Notebook Dell Inspiron 15",
      "rating": "4.5",
      "reviews_count": "1234",
      "image_url": "https://...",
      "price": "2499.99"
    }
  ]
}
```

**Resposta de Erro:**
```json
{
  "success": false,
  "error": "ParÃ¢metro 'keyword' Ã© obrigatÃ³rio",
  "message": "Por favor, forneÃ§a uma palavra-chave para pesquisar"
}
```

#### 3. InformaÃ§Ãµes da API
```http
GET /info
```

**Resposta:**
```json
{
  "name": "Amazon Scraper API",
  "version": "1.0.0",
  "description": "API para fazer scraping de produtos da Amazon",
  "endpoints": {
    "/api/scrape": {
      "method": "GET",
      "description": "Faz scraping de produtos da Amazon",
      "parameters": {
        "keyword": "string (obrigatÃ³rio) - palavra-chave para pesquisar",
        "max_products": "integer (opcional) - nÃºmero mÃ¡ximo de produtos (1-50, padrÃ£o: 20)"
      },
      "example": "/api/scrape?keyword=notebook&max_products=10"
    }
  }
}
```

## ğŸ“ Estrutura do Projeto

```
amazon-scraper/
â”œâ”€â”€ backend/                    # Backend Flask
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ routes/            # Blueprints da API
â”‚   â”‚   â”‚   â”œâ”€â”€ scraper.py     # Endpoints de scraping
â”‚   â”‚   â”‚   â””â”€â”€ user.py        # Endpoints de usuÃ¡rio (template)
â”‚   â”‚   â”œâ”€â”€ models/            # Modelos de dados
â”‚   â”‚   â”œâ”€â”€ static/            # Arquivos estÃ¡ticos
â”‚   â”‚   â”œâ”€â”€ database/          # Banco de dados SQLite
â”‚   â”‚   â”œâ”€â”€ main.py            # Arquivo principal do Flask
â”‚   â”‚   â””â”€â”€ scraper.py         # LÃ³gica de web scraping
â”‚   â”œâ”€â”€ venv/                  # Ambiente virtual Python
â”‚   â””â”€â”€ requirements.txt       # DependÃªncias Python
â”œâ”€â”€ frontend/                  # Frontend Vite
â”‚   â”œâ”€â”€ src/                   # CÃ³digo fonte (se usando framework)
â”‚   â”œâ”€â”€ index.html             # PÃ¡gina principal
â”‚   â”œâ”€â”€ main.js                # JavaScript principal
â”‚   â”œâ”€â”€ style.css              # Estilos CSS
â”‚   â”œâ”€â”€ package.json           # DependÃªncias Node.js
â”‚   â””â”€â”€ vite.config.js         # ConfiguraÃ§Ã£o Vite
â”œâ”€â”€ README.md                  # Este arquivo
â””â”€â”€ todo.md                    # Lista de tarefas do projeto
```

### Arquivos Principais

#### Backend
- **`src/main.py`**: Ponto de entrada da aplicaÃ§Ã£o Flask
- **`src/scraper.py`**: Classe principal para web scraping da Amazon
- **`src/routes/scraper.py`**: Endpoints da API de scraping
- **`requirements.txt`**: Lista de dependÃªncias Python

#### Frontend
- **`index.html`**: Estrutura HTML da aplicaÃ§Ã£o
- **`main.js`**: LÃ³gica JavaScript e integraÃ§Ã£o com API
- **`style.css`**: Estilos CSS responsivos
- **`package.json`**: ConfiguraÃ§Ã£o e dependÃªncias Node.js

## ğŸ› ï¸ Tecnologias Utilizadas

### Backend
- **[Flask](https://flask.palletsprojects.com/)** - Framework web Python
- **[Flask-CORS](https://flask-cors.readthedocs.io/)** - Suporte a CORS
- **[Requests](https://requests.readthedocs.io/)** - Cliente HTTP
- **[BeautifulSoup4](https://www.crummy.com/software/BeautifulSoup/)** - Parser HTML/XML
- **[lxml](https://lxml.de/)** - Parser XML/HTML rÃ¡pido

### Frontend
- **[Vite](https://vitejs.dev/)** - Build tool e dev server
- **HTML5** - Estrutura da pÃ¡gina
- **CSS3** - Estilos e layout responsivo
- **JavaScript (ES6+)** - LÃ³gica da aplicaÃ§Ã£o
- **[Font Awesome](https://fontawesome.com/)** - Ãcones
- **[Google Fonts](https://fonts.google.com/)** - Tipografia

### Ferramentas de Desenvolvimento
- **Python 3.11** - Linguagem do backend
- **Node.js 20** - Runtime JavaScript
- **npm** - Gerenciador de pacotes
- **Git** - Controle de versÃ£o

## âš ï¸ LimitaÃ§Ãµes e ConsideraÃ§Ãµes

### LimitaÃ§Ãµes TÃ©cnicas

1. **ProteÃ§Ãµes Anti-Bot da Amazon**
   - A Amazon implementa vÃ¡rias proteÃ§Ãµes contra web scraping
   - CAPTCHAs podem ser exibidos para requisiÃ§Ãµes automatizadas
   - Rate limiting pode bloquear muitas requisiÃ§Ãµes consecutivas

2. **Estrutura HTML DinÃ¢mica**
   - A Amazon frequentemente altera a estrutura HTML das pÃ¡ginas
   - Seletores CSS podem precisar de atualizaÃ§Ãµes periÃ³dicas
   - ConteÃºdo carregado via JavaScript pode nÃ£o ser capturado

3. **GeolocalizaÃ§Ã£o**
   - Resultados podem variar baseado na localizaÃ§Ã£o do servidor
   - PreÃ§os e disponibilidade sÃ£o especÃ­ficos por regiÃ£o

### ConsideraÃ§Ãµes Legais

1. **Termos de ServiÃ§o**
   - Verifique os termos de serviÃ§o da Amazon antes do uso
   - Web scraping pode violar os termos de uso de alguns sites

2. **Uso ResponsÃ¡vel**
   - Implemente delays entre requisiÃ§Ãµes
   - Respeite o arquivo robots.txt
   - NÃ£o sobrecarregue os servidores

3. **Dados Pessoais**
   - NÃ£o colete informaÃ§Ãµes pessoais de usuÃ¡rios
   - Respeite a privacidade e proteÃ§Ã£o de dados

### Melhorias Futuras

1. **Proxy e RotaÃ§Ã£o de IP**
   - Implementar rotaÃ§Ã£o de proxies
   - Usar serviÃ§os de proxy residencial

2. **Cache e PersistÃªncia**
   - Implementar cache de resultados
   - Salvar dados em banco de dados

3. **Monitoramento**
   - Logs detalhados de requisiÃ§Ãµes
   - MÃ©tricas de performance

4. **Testes Automatizados**
   - Testes unitÃ¡rios para funÃ§Ãµes de scraping
   - Testes de integraÃ§Ã£o da API

## ğŸ¤ ContribuiÃ§Ã£o

ContribuiÃ§Ãµes sÃ£o bem-vindas! Para contribuir:

1. FaÃ§a um fork do projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

### Diretrizes de ContribuiÃ§Ã£o

- Mantenha o cÃ³digo limpo e bem documentado
- Adicione testes para novas funcionalidades
- Siga as convenÃ§Ãµes de cÃ³digo existentes
- Atualize a documentaÃ§Ã£o quando necessÃ¡rio

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ğŸ“ Suporte

Se vocÃª encontrar problemas ou tiver dÃºvidas:

1. Verifique a seÃ§Ã£o de [LimitaÃ§Ãµes](#limitaÃ§Ãµes-e-consideraÃ§Ãµes)
2. Consulte os logs do backend para erros detalhados
3. Abra uma issue no repositÃ³rio do projeto

---

**Desenvolvido com â¤ï¸ por [Manus AI](https://manus.ai)**

